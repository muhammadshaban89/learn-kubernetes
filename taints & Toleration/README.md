Taints and tolerations in Kubernetes:
----------------------------------------
* Kubernetes scheduler  assign newly created pods to the most appropriate nodes in the cluster based on resource availability, constraints, and policies.
* but if you want to assign pod to specific node taints and tolerations are used.
* Taints and tolerations in Kubernetes control which pods can be scheduled on which nodes,  allowing fine-grained placement and isolation of workloads.


What Are Taints?
----------------

A **taint** is applied to a node to repel pods that don‚Äôt explicitly tolerate it. It consists of:

- **Key**:     Identifier for the taint (e.g., `key=dedicated`)
  
- **Value**:   Optional value (e.g., `value=frontend`)
  
- **Effect**:   Determines the behavior (`NoSchedule`, `PreferNoSchedule`, or `NoExecute`)

**Example:**

	kubectl taint nodes node1 dedicated=frontend:NoSchedule

This means: *‚ÄúDon‚Äôt schedule any pod on `node1` unless it tolerates the `dedicated=frontend` taint.‚Äù*

**To check node is taineted or nor not:**

	kubectl describe node <node-name> | grep Taint

**You can taint a node with multiple keys:**

	kubectl taint nodes node1 env=prod:NoSchedule
	kubectl taint nodes node1 gpu=true:NoExecute
	kubectl taint nodes node1 zone=us-west:PreferNoSchedule
	
**How It Works**

- A pod must tolerate all taints on a node to be scheduled there.
- If a pod tolerates only one or two of the taints, it will still be repelled by the others.
- You can define multiple tolerations in the pod spec to match multiple taints.
  
What Are Tolerations?
---------------------

A **toleration** is applied to a pod. It allows the pod to be scheduled on nodes with matching taints.

Example:

    apiVersion: v1
	kind: Pod
	metadata:
 	 name: mypod
	spec:
 	  containers:
 		 - name: mycontainer
  			  image: nginx
	  tolerations:
		- key: key1
 		  operator: Equal
  		  value: value1
 		   effect: NoSchedule


This pod can now be scheduled on nodes tainted with `dedicated=frontend:NoSchedule`.

‚öôÔ∏è Taint Effects Explained

* NoSchedule:      Pod won‚Äôt be scheduled unless it has a matching toleration.              
* PreferNoSchedule: Scheduler avoids the node unless no better options are available.     
* NoExecute: Existing pods without toleration are evicted; new ones won‚Äôt be scheduled.


**Removing a Taint**

To remove a taint:

	kubectl taint nodes node1 dedicated=frontend:NoSchedule-
 
üß† **Use Cases**

- **Dedicated nodes**: Reserve nodes for specific workloads (e.g., GPU, logging).
- **Isolation**: Prevent critical workloads from being scheduled on general-purpose nodes.
- **Eviction control**: Use `NoExecute` to evict pods from nodes under maintenance or failure.

why taints and toleration if nodeselectors also available?
----------------------------------------------------------

Taints and tolerations are used to repel pods from nodes unless explicitly tolerated, while nodeSelectors are used to attract pods to specific nodes. They serve different purposes and offer different levels of control

üß† **When to Use Each**

‚úÖ Use NodeSelectors or Node Affinity when:

- You want to attract pods to specific nodes (e.g., zone=us-west)
- You‚Äôre guiding placement based on hardware, region, or labels
- You don‚Äôt need to enforce strict exclusion
  
‚úÖ Use Taints and Tolerations when:

- You want to repel all pods from a node unless they explicitly tolerate it
- You need to reserve nodes for critical workloads
- You want to evict pods from a node under certain conditions (e.g., maintenance, failure)

**Real-World Example:**

Let‚Äôs say you have GPU nodes:

- Taint the GPU nodes:
  
 		kubectl taint nodes gpu-node gpu=true:NoSchedule
  
- Only allow GPU workloads:

		tolerations:
		- key: "gpu"
 	      operator: "Equal"
          value: "true"
          effect: "NoSchedule"

This ensures only GPU-tolerant pods land on GPU nodes ‚Äî even if other pods have matching nodeSelectors.


